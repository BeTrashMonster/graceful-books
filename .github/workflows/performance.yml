name: Performance Monitoring

on:
  pull_request:
    branches: [main, master]
  push:
    branches: [main, master]

# Cancel in-progress runs for the same workflow and branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  bundle-size:
    name: Bundle Size Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history for accurate comparisons

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Download previous bundle analysis
        uses: dawidd6/action-download-artifact@v3
        continue-on-error: true
        with:
          workflow: performance.yml
          name: bundle-analysis
          path: .benchmarks
          if_no_artifact_found: ignore

      - name: Analyze bundle size
        id: bundle-analysis
        run: node scripts/bundle-size-check.js
        continue-on-error: true

      - name: Upload bundle analysis
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: .benchmarks/
          retention-days: 90

      - name: Comment bundle size on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const reportPath = '.benchmarks/bundle-size-report.md';

            if (fs.existsSync(reportPath)) {
              const report = fs.readFileSync(reportPath, 'utf8');

              // Find existing comment
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
              });

              const botComment = comments.find(comment =>
                comment.user.type === 'Bot' &&
                comment.body.includes('ðŸ“¦ Bundle Size Report')
              );

              const commentBody = `${report}\n\n---\n*Generated by Performance Monitoring CI*`;

              if (botComment) {
                // Update existing comment
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: botComment.id,
                  body: commentBody,
                });
              } else {
                // Create new comment
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: commentBody,
                });
              }
            }

      - name: Fail on bundle size regression
        if: steps.bundle-analysis.outcome == 'failure'
        run: |
          echo "âŒ Bundle size check failed!"
          exit 1

  build-benchmark:
    name: Build Time Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download previous build benchmarks
        uses: dawidd6/action-download-artifact@v3
        continue-on-error: true
        with:
          workflow: performance.yml
          name: build-benchmarks
          path: .benchmarks
          if_no_artifact_found: ignore

      - name: Run build benchmark
        id: build-benchmark
        run: node scripts/benchmark-build.js
        continue-on-error: true

      - name: Upload build benchmarks
        uses: actions/upload-artifact@v4
        with:
          name: build-benchmarks
          path: .benchmarks/build-times.json
          retention-days: 90

      - name: Fail on build regression
        if: steps.build-benchmark.outcome == 'failure'
        run: |
          echo "âŒ Build time regression detected!"
          exit 1

  test-benchmark:
    name: Test Execution Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download previous test benchmarks
        uses: dawidd6/action-download-artifact@v3
        continue-on-error: true
        with:
          workflow: performance.yml
          name: test-benchmarks
          path: .benchmarks
          if_no_artifact_found: ignore

      - name: Run test benchmark
        id: test-benchmark
        run: node scripts/benchmark-tests.js
        continue-on-error: true

      - name: Upload test benchmarks
        uses: actions/upload-artifact@v4
        with:
          name: test-benchmarks
          path: .benchmarks/test-times.json
          retention-days: 90

      - name: Fail on test regression
        if: steps.test-benchmark.outcome == 'failure'
        run: |
          echo "âŒ Test execution time regression detected!"
          exit 1

  lighthouse:
    name: Lighthouse CI
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.13.x

      - name: Run Lighthouse CI
        id: lighthouse
        run: lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
        continue-on-error: true

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-results
          path: .lighthouseci
          retention-days: 30

      - name: Comment Lighthouse scores on PR
        if: github.event_name == 'pull_request'
        uses: treosh/lighthouse-ci-action@v11
        with:
          uploadArtifacts: true
          temporaryPublicStorage: true
          configPath: './lighthouserc.js'

      - name: Fail on Lighthouse regression
        if: steps.lighthouse.outcome == 'failure'
        run: |
          echo "âŒ Lighthouse performance regression detected!"
          exit 1

  performance-dashboard:
    name: Generate Performance Dashboard
    runs-on: ubuntu-latest
    needs: [bundle-size, build-benchmark, test-benchmark, lighthouse]
    if: github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main'
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all benchmarks
        uses: actions/download-artifact@v4
        with:
          path: .benchmarks

      - name: Generate performance dashboard
        run: |
          echo "# Performance Dashboard" > .benchmarks/dashboard.md
          echo "" >> .benchmarks/dashboard.md
          echo "ðŸ“Š Performance metrics tracked across time." >> .benchmarks/dashboard.md
          echo "" >> .benchmarks/dashboard.md
          echo "Last updated: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> .benchmarks/dashboard.md
          echo "" >> .benchmarks/dashboard.md

          # Add bundle size trend if available
          if [ -f ".benchmarks/bundle-analysis/bundle-sizes.json" ]; then
            echo "## Bundle Size Trend" >> .benchmarks/dashboard.md
            echo "" >> .benchmarks/dashboard.md
            echo "See bundle-size-report.md for details." >> .benchmarks/dashboard.md
            echo "" >> .benchmarks/dashboard.md
          fi

          # Add build time trend if available
          if [ -f ".benchmarks/build-benchmarks/build-times.json" ]; then
            echo "## Build Time Trend" >> .benchmarks/dashboard.md
            echo "" >> .benchmarks/dashboard.md
            echo "Historical build times tracked in build-times.json" >> .benchmarks/dashboard.md
            echo "" >> .benchmarks/dashboard.md
          fi

          # Add test time trend if available
          if [ -f ".benchmarks/test-benchmarks/test-times.json" ]; then
            echo "## Test Execution Trend" >> .benchmarks/dashboard.md
            echo "" >> .benchmarks/dashboard.md
            echo "Historical test execution times tracked in test-times.json" >> .benchmarks/dashboard.md
            echo "" >> .benchmarks/dashboard.md
          fi

      - name: Upload performance dashboard
        uses: actions/upload-artifact@v4
        with:
          name: performance-dashboard
          path: .benchmarks/dashboard.md
          retention-days: 90

  # Status check job that all performance checks depend on
  performance-success:
    name: Performance Checks Success
    runs-on: ubuntu-latest
    needs: [bundle-size, build-benchmark, test-benchmark, lighthouse]
    if: always()

    steps:
      - name: Check if all jobs passed
        run: |
          if [[ "${{ needs.bundle-size.result }}" != "success" || \
                "${{ needs.build-benchmark.result }}" != "success" || \
                "${{ needs.test-benchmark.result }}" != "success" || \
                "${{ needs.lighthouse.result }}" != "success" ]]; then
            echo "One or more performance checks failed"
            exit 1
          fi
          echo "All performance checks passed!"
